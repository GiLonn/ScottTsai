{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import math\n",
    "import data_loader\n",
    "import resnet as models\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import KMM_Lin\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(model, target_test_loader):\n",
    "# #     model.eval() # 讓模型變成測試模式，主要針對Dropout與Batch Normalization在train與eval的不同設置模式\n",
    "# #     test_loss = utils.AverageMeter() # Computes and stores the average and current value\n",
    "#     correct_total = 0.\n",
    "#     count_stack = 0\n",
    "#     criterion = torch.nn.CrossEntropyLoss() # 定義一個標準準則，用來計算loss (讓輸出經過softmax，再進入Cross Entropy)\n",
    "#     len_target_dataset = len(target_test_loader.dataset) #所有test資料集的總數\n",
    "#     with torch.no_grad(): # 在做evaluation時，關閉計算導數來增加運行速度\n",
    "#         for data, target in target_test_loader: # data為test資料，target為test label\n",
    "#             data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "#             s_output = model.predict(data) # 將data放入模型得到預測的輸出\n",
    "#             loss = criterion(s_output, target) #計算loss\n",
    "# #             test_loss.update(loss.item()) # 更新值到紀錄中\n",
    "\n",
    "#             # torch.max(a,1) 返回每一列中最大值的那個元素，且返回其索引\n",
    "#             # troch.max()[1] 只返回最大值的每個索引\n",
    "#             pred = torch.max(s_output, 1)[1]\n",
    "#             correct_total += torch.sum(pred == target)\n",
    "\n",
    "# #             pred_matrix = pred.data\n",
    "# #             target_matrix = target.data\n",
    "#             # print(\"pred_matrix、target_matrix\")\n",
    "#             # print(pred_matrix,target_matrix)\n",
    "# #             if count_stack == 0:\n",
    "# #                 pred_matrix_total = pred_matrix\n",
    "# #                 target_matrix_total = target_matrix\n",
    "# #                 count_stack =1\n",
    "# #             elif count_stack == 1:\n",
    "# #                 pred_matrix_total = torch.cat((pred_matrix_total,pred_matrix))\n",
    "# #                 target_matrix_total = torch.cat((target_matrix_total,target_matrix))\n",
    "\n",
    "#             # print(\"pred_matrix_total、target_matrix_total\")\n",
    "#             # print(pred_matrix_total, target_matrix_total)\n",
    "# #         target_matrix_total = target_matrix_total.cpu().numpy()\n",
    "# #         pred_matrix_total = pred_matrix_total.cpu().numpy()\n",
    "# #         tn, fp, fn, tp = confusion_matrix(target_matrix_total, pred_matrix_total,labels=[0,1]).ravel()\n",
    "#         # print(tn, fp, fn, tp)\n",
    "#     # correct = correct.cpu().numpy()\n",
    "#     # {:.2f}保留小數點後兩位\n",
    "#     # print(correct)\n",
    "#     # print(correct/300.)\n",
    "#     # print('{:.3f}'.format(correct/len_target_dataset))\n",
    "#     test_total = 100*correct_total.type(torch.float32)/len_target_dataset\n",
    "#     print('test max correct: {}, test accuracy: {:.3f} % \\n'.format(correct_total, test_total))\n",
    "\n",
    "# #     logtest.append([test_total,tn, fp, fn, tp])\n",
    "# #     np_log = np.array(logtest, dtype=float)\n",
    "#     # delimiter : 分隔浮號 ； %.6f 浮點型保留六位小數\n",
    "# #     np.savetxt(opt.save_test_name, np_log, delimiter=',', fmt='%.6f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0.\n",
    "    correct1 = 0\n",
    "    correct2 = 0\n",
    "    correct3 = 0\n",
    "    correct4 = 0\n",
    "    count_stack = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in target_test_loader:\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            pred1, pred2, pred3, pred4 = model(data)\n",
    "\n",
    "            pred1 = torch.nn.functional.softmax(pred1, dim=1)\n",
    "            pred2 = torch.nn.functional.softmax(pred2, dim=1)\n",
    "            pred3 = torch.nn.functional.softmax(pred3, dim=1)\n",
    "            pred4 = torch.nn.functional.softmax(pred4, dim=1)\n",
    "\n",
    "            pred = (pred1 + pred2 + pred3 + pred4) / 4\n",
    "            test_loss += F.nll_loss(F.log_softmax(pred, dim=1), target).item()  # sum up batch loss\n",
    "\n",
    "            pred = pred.data.max(1)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "            pred = pred1.data.max(1)[1]  # get the index of the max log-probability\n",
    "            correct1 += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "            pred = pred2.data.max(1)[1]  # get the index of the max log-probability\n",
    "            correct2 += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "            pred = pred3.data.max(1)[1]  # get the index of the max log-probability\n",
    "            correct3 += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "            pred = pred4.data.max(1)[1]  # get the index of the max log-probability\n",
    "            correct4 += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "#             pred_matrix = pred.data\n",
    "#             target_matrix = target.data\n",
    "#             if count_stack == 0:\n",
    "#                 pred_matrix_total = pred_matrix\n",
    "#                 target_matrix_total = target_matrix\n",
    "#                 count_stack =1\n",
    "#             elif count_stack == 1:\n",
    "#                 pred_matrix_total = torch.cat((pred_matrix_total,pred_matrix))\n",
    "#                 target_matrix_total = torch.cat((target_matrix_total,target_matrix))\n",
    "\n",
    "#         target_matrix_total = target_matrix_total.cpu().numpy()\n",
    "#         pred_matrix_total = pred_matrix_total.cpu().numpy()\n",
    "#         tn, fp, fn, tp = confusion_matrix(target_matrix_total, pred_matrix_total,labels=[0,1]).ravel()\n",
    "\n",
    "        test_loss /= len(target_test_loader.dataset)\n",
    "        print(target_test_name, '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, correct.type(torch.float32), len(target_test_loader.dataset),100. * correct.type(torch.float32) / len(target_test_loader.dataset)))\n",
    "        \n",
    "        print('\\nsource1 accnum {}, source2 accnum {}，source3 accnum {}，source4 accnum {}'.format(\n",
    "            correct1.type(torch.float32), correct2.type(torch.float32), correct3.type(torch.float32), correct4.type(torch.float32)))\n",
    "\n",
    "        test_total = 100*correct.type(torch.float32)/len(target_test_loader.dataset)\n",
    "\n",
    "#         logtest.append([test_total,tn, fp, fn, tp,correct1,correct2,correct3,correct4])\n",
    "#         np_log = np.array(logtest, dtype=float)\n",
    "#         np.savetxt(opt.save_test_name, np_log, delimiter=',', fmt='%.6f')\n",
    "\n",
    "    return correct.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(root_dir):\n",
    "#     batch_size = 8\n",
    "#     folder_test = root_dir\n",
    "#     target_test_loader,test_index = data_loader.load_data(folder_test, batch_size, False, CFG['kwargs'])\n",
    "#     return target_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cuda = True\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if cuda else {}\n",
    "root_path = \"E:\\\\AmigoChou\\\\Q2\\Training\\\\M2O_datasets\\\\instance\\\\4_to_1\\\\_to_pear\\\\59\"\n",
    "target_test_name = \"\\\\target\\\\test\"\n",
    "batch_size = 8\n",
    "\n",
    "target_test_loader = data_loader.load_testing(root_path, target_test_name, batch_size, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MFSAN(\n",
       "  (sharedNet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (sonnet1): ADDneck(\n",
       "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "  )\n",
       "  (sonnet2): ADDneck(\n",
       "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "  )\n",
       "  (sonnet3): ADDneck(\n",
       "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "  )\n",
       "  (sonnet4): ADDneck(\n",
       "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "  )\n",
       "  (cls_fc_son1): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (cls_fc_son2): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (cls_fc_son3): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (cls_fc_son4): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.MFSAN(num_classes=2)\n",
    "model.load_state_dict(torch.load('E:\\\\AmigoChou\\\\Q2\\\\Training\\\\M2O_LXZ_editbyAmigo\\\\4_to_1\\\\log_model\\\\_to_pear\\\\59_1\\\\model_mmd_parameter_1_log0.pkl'))\n",
    "model.cuda()\n",
    "model.eval()\n",
    "# model = torch.load('model_parameter_1_log1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\target\\test \n",
      "Test set: Average loss: 0.0747, Accuracy: 502.0/600 (83.67%)\n",
      "\n",
      "\n",
      "source1 accnum 470.0, source2 accnum 470.0，source3 accnum 435.0，source4 accnum 538.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(502.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_test_loader = load_data('E:\\\\AmigoChou\\\\Q2\\\\Training\\\\O2M_LXZ vs ZYM\\\\datasets\\\\O2M_datasets_backup\\\\apple_to_\\\\to_pear\\\\sn_200_sp_200\\\\target\\\\test')\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2eServer",
   "language": "python",
   "name": "e2eserver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
